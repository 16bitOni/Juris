{
  "best_metric": 0.2570638954639435,
  "best_model_checkpoint": "./gpt2-indian-legal\\checkpoint-4000",
  "epoch": 2.444987775061125,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.061124694376528114,
      "grad_norm": 0.23155450820922852,
      "learning_rate": 4.898125509372453e-05,
      "loss": 2.3976,
      "step": 100
    },
    {
      "epoch": 0.12224938875305623,
      "grad_norm": 0.16778168082237244,
      "learning_rate": 4.796251018744907e-05,
      "loss": 0.3097,
      "step": 200
    },
    {
      "epoch": 0.18337408312958436,
      "grad_norm": 0.13301539421081543,
      "learning_rate": 4.69437652811736e-05,
      "loss": 0.2839,
      "step": 300
    },
    {
      "epoch": 0.24449877750611246,
      "grad_norm": 0.12291987985372543,
      "learning_rate": 4.5925020374898124e-05,
      "loss": 0.2672,
      "step": 400
    },
    {
      "epoch": 0.3056234718826406,
      "grad_norm": 0.14003972709178925,
      "learning_rate": 4.490627546862266e-05,
      "loss": 0.257,
      "step": 500
    },
    {
      "epoch": 0.3056234718826406,
      "eval_loss": 0.2709433138370514,
      "eval_runtime": 231.1331,
      "eval_samples_per_second": 6.295,
      "eval_steps_per_second": 3.15,
      "step": 500
    },
    {
      "epoch": 0.36674816625916873,
      "grad_norm": 0.12344125658273697,
      "learning_rate": 4.388753056234719e-05,
      "loss": 0.2538,
      "step": 600
    },
    {
      "epoch": 0.4278728606356968,
      "grad_norm": 0.11620824038982391,
      "learning_rate": 4.286878565607172e-05,
      "loss": 0.2552,
      "step": 700
    },
    {
      "epoch": 0.4889975550122249,
      "grad_norm": 0.11555632948875427,
      "learning_rate": 4.185004074979625e-05,
      "loss": 0.2513,
      "step": 800
    },
    {
      "epoch": 0.5501222493887531,
      "grad_norm": 0.14093123376369476,
      "learning_rate": 4.0831295843520786e-05,
      "loss": 0.2542,
      "step": 900
    },
    {
      "epoch": 0.6112469437652812,
      "grad_norm": 0.11705772578716278,
      "learning_rate": 3.981255093724531e-05,
      "loss": 0.2514,
      "step": 1000
    },
    {
      "epoch": 0.6112469437652812,
      "eval_loss": 0.2633301317691803,
      "eval_runtime": 269.8967,
      "eval_samples_per_second": 5.391,
      "eval_steps_per_second": 2.697,
      "step": 1000
    },
    {
      "epoch": 0.6723716381418093,
      "grad_norm": 0.1303703784942627,
      "learning_rate": 3.8793806030969846e-05,
      "loss": 0.2467,
      "step": 1100
    },
    {
      "epoch": 0.7334963325183375,
      "grad_norm": 0.2358681857585907,
      "learning_rate": 3.777506112469438e-05,
      "loss": 0.2403,
      "step": 1200
    },
    {
      "epoch": 0.7946210268948656,
      "grad_norm": 0.17413590848445892,
      "learning_rate": 3.675631621841891e-05,
      "loss": 0.2426,
      "step": 1300
    },
    {
      "epoch": 0.8557457212713936,
      "grad_norm": 0.1953715682029724,
      "learning_rate": 3.573757131214344e-05,
      "loss": 0.2389,
      "step": 1400
    },
    {
      "epoch": 0.9168704156479217,
      "grad_norm": 0.14863555133342743,
      "learning_rate": 3.4718826405867974e-05,
      "loss": 0.2394,
      "step": 1500
    },
    {
      "epoch": 0.9168704156479217,
      "eval_loss": 0.2612052857875824,
      "eval_runtime": 283.7469,
      "eval_samples_per_second": 5.128,
      "eval_steps_per_second": 2.566,
      "step": 1500
    },
    {
      "epoch": 0.9779951100244498,
      "grad_norm": 0.20341965556144714,
      "learning_rate": 3.370008149959251e-05,
      "loss": 0.2436,
      "step": 1600
    },
    {
      "epoch": 1.039119804400978,
      "grad_norm": 0.16820241510868073,
      "learning_rate": 3.2681336593317035e-05,
      "loss": 0.2427,
      "step": 1700
    },
    {
      "epoch": 1.1002444987775062,
      "grad_norm": 0.1501021534204483,
      "learning_rate": 3.166259168704156e-05,
      "loss": 0.2433,
      "step": 1800
    },
    {
      "epoch": 1.1613691931540342,
      "grad_norm": 0.1589382439851761,
      "learning_rate": 3.06438467807661e-05,
      "loss": 0.2432,
      "step": 1900
    },
    {
      "epoch": 1.2224938875305624,
      "grad_norm": 0.1528729945421219,
      "learning_rate": 2.962510187449063e-05,
      "loss": 0.247,
      "step": 2000
    },
    {
      "epoch": 1.2224938875305624,
      "eval_loss": 0.2597595453262329,
      "eval_runtime": 246.2456,
      "eval_samples_per_second": 5.909,
      "eval_steps_per_second": 2.956,
      "step": 2000
    },
    {
      "epoch": 1.2836185819070904,
      "grad_norm": 0.2261940836906433,
      "learning_rate": 2.860635696821516e-05,
      "loss": 0.2382,
      "step": 2100
    },
    {
      "epoch": 1.3447432762836184,
      "grad_norm": 0.1291428506374359,
      "learning_rate": 2.7587612061939694e-05,
      "loss": 0.2393,
      "step": 2200
    },
    {
      "epoch": 1.4058679706601467,
      "grad_norm": 0.13741271197795868,
      "learning_rate": 2.6568867155664224e-05,
      "loss": 0.24,
      "step": 2300
    },
    {
      "epoch": 1.466992665036675,
      "grad_norm": 0.18057993054389954,
      "learning_rate": 2.5550122249388754e-05,
      "loss": 0.2407,
      "step": 2400
    },
    {
      "epoch": 1.528117359413203,
      "grad_norm": 0.1492171585559845,
      "learning_rate": 2.4531377343113285e-05,
      "loss": 0.2367,
      "step": 2500
    },
    {
      "epoch": 1.528117359413203,
      "eval_loss": 0.2592479884624481,
      "eval_runtime": 246.4601,
      "eval_samples_per_second": 5.904,
      "eval_steps_per_second": 2.954,
      "step": 2500
    },
    {
      "epoch": 1.589242053789731,
      "grad_norm": 0.20394398272037506,
      "learning_rate": 2.351263243683782e-05,
      "loss": 0.2343,
      "step": 2600
    },
    {
      "epoch": 1.6503667481662592,
      "grad_norm": 0.17543363571166992,
      "learning_rate": 2.249388753056235e-05,
      "loss": 0.2358,
      "step": 2700
    },
    {
      "epoch": 1.7114914425427874,
      "grad_norm": 0.13125434517860413,
      "learning_rate": 2.147514262428688e-05,
      "loss": 0.2303,
      "step": 2800
    },
    {
      "epoch": 1.7726161369193154,
      "grad_norm": 0.14457128942012787,
      "learning_rate": 2.045639771801141e-05,
      "loss": 0.2457,
      "step": 2900
    },
    {
      "epoch": 1.8337408312958434,
      "grad_norm": 0.1366974264383316,
      "learning_rate": 1.9437652811735943e-05,
      "loss": 0.2333,
      "step": 3000
    },
    {
      "epoch": 1.8337408312958434,
      "eval_loss": 0.2584083080291748,
      "eval_runtime": 278.4166,
      "eval_samples_per_second": 5.226,
      "eval_steps_per_second": 2.615,
      "step": 3000
    },
    {
      "epoch": 1.8948655256723717,
      "grad_norm": 0.14780929684638977,
      "learning_rate": 1.8418907905460474e-05,
      "loss": 0.2352,
      "step": 3100
    },
    {
      "epoch": 1.9559902200488999,
      "grad_norm": 0.18008193373680115,
      "learning_rate": 1.7400162999185004e-05,
      "loss": 0.2299,
      "step": 3200
    },
    {
      "epoch": 2.0171149144254277,
      "grad_norm": 0.1462690532207489,
      "learning_rate": 1.6381418092909538e-05,
      "loss": 0.2289,
      "step": 3300
    },
    {
      "epoch": 2.078239608801956,
      "grad_norm": 0.15381571650505066,
      "learning_rate": 1.5362673186634065e-05,
      "loss": 0.2315,
      "step": 3400
    },
    {
      "epoch": 2.139364303178484,
      "grad_norm": 0.17633605003356934,
      "learning_rate": 1.4343928280358598e-05,
      "loss": 0.2339,
      "step": 3500
    },
    {
      "epoch": 2.139364303178484,
      "eval_loss": 0.257804811000824,
      "eval_runtime": 297.8181,
      "eval_samples_per_second": 4.886,
      "eval_steps_per_second": 2.444,
      "step": 3500
    },
    {
      "epoch": 2.2004889975550124,
      "grad_norm": 0.15820281207561493,
      "learning_rate": 1.332518337408313e-05,
      "loss": 0.2278,
      "step": 3600
    },
    {
      "epoch": 2.26161369193154,
      "grad_norm": 0.17090633511543274,
      "learning_rate": 1.230643846780766e-05,
      "loss": 0.2327,
      "step": 3700
    },
    {
      "epoch": 2.3227383863080684,
      "grad_norm": 0.1820043921470642,
      "learning_rate": 1.1287693561532194e-05,
      "loss": 0.2369,
      "step": 3800
    },
    {
      "epoch": 2.3838630806845966,
      "grad_norm": 0.197068989276886,
      "learning_rate": 1.0268948655256725e-05,
      "loss": 0.2416,
      "step": 3900
    },
    {
      "epoch": 2.444987775061125,
      "grad_norm": 0.16294310986995697,
      "learning_rate": 9.250203748981255e-06,
      "loss": 0.232,
      "step": 4000
    },
    {
      "epoch": 2.444987775061125,
      "eval_loss": 0.2570638954639435,
      "eval_runtime": 262.9019,
      "eval_samples_per_second": 5.534,
      "eval_steps_per_second": 2.769,
      "step": 4000
    }
  ],
  "logging_steps": 100,
  "max_steps": 4908,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8441070354432000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
